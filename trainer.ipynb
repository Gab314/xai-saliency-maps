{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5308,
     "status": "ok",
     "timestamp": 1670763854937,
     "user": {
      "displayName": "Gabriel Kotani",
      "userId": "12444054821119454536"
     },
     "user_tz": 180
    },
    "id": "ExjU0i-R2r7H",
    "outputId": "08f29df4-0025-4315-912b-854f9b899f84",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "import tensorflow as tf\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 1707,
     "status": "ok",
     "timestamp": 1670763870502,
     "user": {
      "displayName": "Gabriel Kotani",
      "userId": "12444054821119454536"
     },
     "user_tz": 180
    },
    "id": "8OWxCgQfFqHe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.ndimage import rotate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "    \n",
    "    \n",
    "# --------------------------------------------------LOAD DATA------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def loadData(dataset_folder, \n",
    "             test_folder, \n",
    "             columns, \n",
    "             batch_size, \n",
    "             input_shape,\n",
    "            ):\n",
    "    \n",
    "    # step 1\n",
    "    train_files = [f\"data/{dataset_folder}/{x}\" for x in os.listdir(f\"data/{dataset_folder}\")]\n",
    "    test_files = [f\"data/{test_folder}/{x}\" for x in os.listdir(f\"data/{test_folder}\")]\n",
    "\n",
    "    train_df = pd.read_parquet(f\"data/{dataset_folder}_dataset.parquet.gzip\")\n",
    "    test_df = pd.read_parquet(f\"data/{test_folder}_dataset.parquet.gzip\")\n",
    "    \n",
    "    train_df.index = f\"data/{dataset_folder}/\" + train_df[\"file\"]\n",
    "    test_df.index =  f\"data/{test_folder}/\" + test_df[\"file\"]\n",
    "    \n",
    "    train_df.drop(columns=['file'], inplace=True)\n",
    "    test_df.drop(columns=['file'], inplace=True)\n",
    "\n",
    "    train_y = train_df.loc[train_files][columns].to_numpy()\n",
    "    test_y =test_df.loc[test_files][columns].to_numpy()\n",
    "    \n",
    "        \n",
    "    def augment(im):\n",
    "        \n",
    "        pad_size = random.randint(0, 24)\n",
    "        im = tf.image.resize(im, [224+pad_size,224+pad_size])\n",
    "        # Flip\n",
    "        im = tf.image.random_flip_left_right(\n",
    "            im, seed=None\n",
    "        )\n",
    "        # Saturation\n",
    "        im = tf.image.random_saturation(\n",
    "            im, 0, 3\n",
    "        )\n",
    "        # Contrast\n",
    "        im = tf.image.random_contrast(\n",
    "            im, 0.5, 1\n",
    "        )\n",
    "        # Brightness\n",
    "        im = tf.image.random_brightness(\n",
    "            im, 0.4\n",
    "        )\n",
    "        #Crop\n",
    "\n",
    "        # pad_size = random.randint(0, 24)\n",
    "        size = 224\n",
    "\n",
    "        padded = np.ones((size+24, size+24, 3))\n",
    "        x_shift = random.randint(0, 24 - pad_size)\n",
    "        y_shift = random.randint(0, 24 - pad_size)\n",
    "        xMax = size + pad_size + x_shift\n",
    "        yMax = size + pad_size + y_shift\n",
    "        padded[y_shift : yMax, x_shift : xMax, :] = im\n",
    "\n",
    "        x_shift = random.randint(0, pad_size)\n",
    "        y_shift = random.randint(0, pad_size)\n",
    "        im = padded[y_shift:size+y_shift, x_shift:size+x_shift, :]\n",
    "\n",
    "        return im\n",
    "\n",
    "    \n",
    "    \n",
    "    def im_file_to_tensor(file, label):\n",
    "        \n",
    "        def _transform(im, label):\n",
    "            im = augment(im)\n",
    "            im = tf.cast(im, tf.float32) / 255.0\n",
    "            label = tf.cast(label, tf.float32)\n",
    "            return im, label\n",
    "        \n",
    "        def _im_file_to_tensor(file, label):\n",
    "            path = file.numpy().decode()\n",
    "            im = tf.image.decode_png(tf.io.read_file(path), channels=3)\n",
    "            im, label = _transform(im, label)\n",
    "            \n",
    "            return im, label\n",
    "        \n",
    "        file, label =  tf.py_function(_im_file_to_tensor, \n",
    "                              inp=(file, label), \n",
    "                              Tout=(tf.float32, tf.float32))\n",
    "\n",
    "        return ({\"image\" : file}, label)\n",
    "    \n",
    "        \n",
    "    train = tf.data.Dataset.from_tensor_slices((train_files, train_y))\n",
    "    test = tf.data.Dataset.from_tensor_slices((test_files, test_y))\n",
    "\n",
    "    train_ds = train.map(im_file_to_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds  = test.map(im_file_to_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    train_ds = train_ds.batch(24, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds  = test_ds.batch(24, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        \n",
    "    return train_ds, test_ds\n",
    "\n",
    "\n",
    "# --------------------------------------------------LOAD MODEL-------------------------------------------------------------------\n",
    "\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense, Concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def loadModel(name, loss, input_shape, output_shape):\n",
    "\n",
    "    resnet = ResNet50V2(include_top=False)\n",
    "    \n",
    "    inputsA = keras.Input(shape=input_shape, name=\"image\")\n",
    "    xA = resnet(inputsA, training=True)\n",
    "    xA = keras.layers.GlobalAveragePooling2D()(xA)\n",
    "    output = Dense(output_shape)(xA)\n",
    "    model = Model(inputs=inputsA, outputs=output)\n",
    "    return model\n",
    "    \n",
    "\n",
    "# --------------------------------------------------TRAIN-------------------------------------------------------------------\n",
    "\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16') # mixed_float16\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "def trainModel(model, train_dataset, test_dataset, model_name, version, epochs, patience, loss):\n",
    "    \n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", verbose=1, patience=patience\n",
    "    )\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=f\"logs/{model_name}_{version}\")\n",
    "    \n",
    "    opt=keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanSquaredError(),\n",
    "            tf.keras.metrics.RootMeanSquaredError()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            tensorboard_callback\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    model.save(f\"model/{model_name}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670763871436,
     "user": {
      "displayName": "Gabriel Kotani",
      "userId": "12444054821119454536"
     },
     "user_tz": 180
    },
    "id": "lvieBdMmIe4Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "DATASET = 'train_aws'\n",
    "TEST_DATASET = 'testA_aws'\n",
    "\n",
    "FULL_DATASET = True\n",
    "MODEL_ONLY = False\n",
    "TRAINING = True\n",
    "SHOW_RESULTS = False\n",
    "\n",
    "PREDICTION_NAME =  ['waist']\n",
    "MODEL_NAME = 'resnet50'\n",
    "MODEL_VERSION = 'v1'\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "OUTPUT_SHAPE = len(PREDICTION_NAME)\n",
    "EPOCHS = 5000\n",
    "PATIENCE = 30\n",
    "BATCH_SIZE = 24\n",
    "LOSS = 'mse'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53495,
     "status": "ok",
     "timestamp": 1670763924921,
     "user": {
      "displayName": "Gabriel Kotani",
      "userId": "12444054821119454536"
     },
     "user_tz": 180
    },
    "id": "sgomyMgxI5Nm",
    "outputId": "8ecd4ba0-219e-4758-c4f0-931d13d59186",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "print('Loading Data')\n",
    "train_dataset, test_dataset = loadData(\n",
    "    DATASET, TEST_DATASET, PREDICTION_NAME, BATCH_SIZE, INPUT_SHAPE\n",
    ")\n",
    "print('Loaded')\n",
    "\n",
    "model = loadModel(MODEL_NAME, LOSS, INPUT_SHAPE, OUTPUT_SHAPE)\n",
    "\n",
    "trainModel(model, train_dataset, test_dataset, MODEL_NAME, MODEL_VERSION, EPOCHS, PATIENCE, LOSS)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
